{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, LSTM\n",
    "import core.preprocessing as pp\n",
    "\n",
    "LOGDIR = \"/tmp/forecasting/\"\n",
    "\n",
    "present_window = 5*12\n",
    "future_window = 3*12\n",
    "\n",
    "# Load data\n",
    "df = pd.read_pickle('data/detrended_master_dataset.pkl').fillna(0)\n",
    "\n",
    "# Drop columns originally filled with NaNs\n",
    "for item in pp.DROP_LIST:\n",
    "    key = 'S{:02}'.format(item)\n",
    "    del df[key]\n",
    "\n",
    "nstamps = df.shape[0]\n",
    "nseries = df.shape[1] - 1\n",
    "\n",
    "# Split into training and dev\n",
    "dftrain = pp.make_small_train(df, 'combined')\n",
    "dfdev = pp.make_small_dev(df)\n",
    "\n",
    "# Define how to produce batches\n",
    "def make_batch(data, size):\n",
    "    features = data.iloc[:,0:-1] # assume inverters are in columns 2, 3, ..., n-1\n",
    "    response = data.iloc[:,-1] # assume aggregate power is in column n\n",
    "    \n",
    "    n = data.shape[0]\n",
    "    \n",
    "    X = []; Y = []\n",
    "    for i in range(size):\n",
    "        t = np.random.randint(n - present_window - future_window)\n",
    "        x = features[t:t+present_window].values.T.flatten().tolist()\n",
    "        y = response[t+present_window:t+present_window+future_window].values.tolist()\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "    return np.array(X, dtype=np.float32), np.array(Y, dtype=np.float32)\n",
    "\n",
    "def center_batch(data):\n",
    "    X = data[0]\n",
    "    Y = data[1]\n",
    "    m = np.mean(X, 0)\n",
    "    s = np.std(X, 0)\n",
    "    Xcent = (X - m) / s\n",
    "    m = np.mean(Y, 0)\n",
    "    s = np.std(Y, 0)\n",
    "    Ycent = (Y - m) / s\n",
    "    return Xcent, Ycent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FC(object):\n",
    "    def __init__(self, layer_units):\n",
    "        nlayers = len(layer_units)\n",
    "        self.layers = []\n",
    "        for i in range(nlayers):\n",
    "            self.layers.append(Dense(layer_units[i], activation=tf.nn.relu))\n",
    "        self.layers.append(Dense(future_window))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        a = x\n",
    "        for l in self.layers:\n",
    "            a = l(a)\n",
    "        return a\n",
    "\n",
    "class CNN(object):\n",
    "    def __init__(self, layer_units):\n",
    "        nlayers = len(layer_units)\n",
    "        self.layers = []\n",
    "        for i in range(nlayers):\n",
    "            self.layers.append(Conv2D(layer_units[i], kernel_size=3, activation=tf.nn.relu, padding='same'))\n",
    "            self.layers.append(MaxPool2D(padding='same'))\n",
    "        self.layers.append(Flatten())\n",
    "        self.layers.append(Dense(future_window))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        a = tf.reshape(x, [-1, nseries, present_window, 1])\n",
    "        for l in self.layers:\n",
    "            a = l(a)\n",
    "        return a\n",
    "    \n",
    "class RNN(object):\n",
    "    def __init__(self):\n",
    "#         self.streams = []\n",
    "        self.layer = LSTM(future_window, input_shape=(future_window, nseries))\n",
    "#         for i in range(nseries):\n",
    "#             stream = []\n",
    "#             stream.append(LSTM(future_window))\n",
    "#             self.streams.append(stream)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        x_img = tf.reshape(x, [-1, nseries, present_window])\n",
    "        \n",
    "        x_img = tf.transpose(x_img, perm=[0,2,1])\n",
    "        return self.layer(x_img)\n",
    "    \n",
    "#         xs = [tf.reshape(x_img[:,i,:], [-1, present_window, 1]) for i in range(nseries)]\n",
    "#         X = tf.concat(xs, 0)\n",
    "#         return X\n",
    "#         ys = []\n",
    "#         for xval in xs:\n",
    "#             ys.append(self.layer(xval))\n",
    "#         return tf.add_n(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def submit(net_model, niter, lr, fname):\n",
    "    # Start clean\n",
    "    tf.reset_default_graph()\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Setup placeholders for input and output\n",
    "    x = tf.placeholder(tf.float32, shape=[None, present_window*nseries], name=\"x\")\n",
    "    y = tf.placeholder(tf.float32, shape=[None, future_window], name=\"y\")\n",
    "    \n",
    "    # Similarly, setup placeholders for dev set\n",
    "    xdev = tf.placeholder(tf.float32, shape=[None, present_window*nseries], name=\"xdev\")\n",
    "    ydev = tf.placeholder(tf.float32, shape=[None, future_window], name=\"ydev\")\n",
    "    \n",
    "    # Feed forward training and dev examples\n",
    "#     with tf.variable_scope(net_model, reuse=tf.AUTO_REUSE):\n",
    "    if net_model is 'CNN':\n",
    "        nn = CNN([32,64])\n",
    "    elif net_model is 'FC':\n",
    "        nn = FC([1024,512])\n",
    "    elif net_model is 'RNN':\n",
    "        nn = RNN()\n",
    "\n",
    "    yhat    = nn(x)\n",
    "    yhatdev = nn(xdev)\n",
    "\n",
    "    # Define loss in training and dev set\n",
    "    with tf.name_scope(\"loss\"):\n",
    "        train_loss = tf.losses.mean_squared_error(labels=y, predictions=yhat)\n",
    "        dev_loss = tf.losses.mean_squared_error(labels=ydev, predictions=yhatdev)\n",
    "        tf.summary.scalar(\"train_loss\", train_loss)\n",
    "        tf.summary.scalar(\"dev_loss\", dev_loss)\n",
    "\n",
    "    # Minimize training loss\n",
    "    with tf.name_scope(\"train\"):\n",
    "        train_step = tf.train.AdamOptimizer(lr).minimize(train_loss)\n",
    "\n",
    "    # Collect all summaries for TensorBoard\n",
    "    summ = tf.summary.merge_all()\n",
    "\n",
    "    # Start of execution\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(LOGDIR + fname)\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    for i in range(niter):\n",
    "        X, Y = make_batch(dftrain, 100)\n",
    "        Xdev, Ydev = make_batch(dfdev, 100)\n",
    "        if i % 5 == 0:\n",
    "            [tloss, dloss, s] = sess.run([train_loss, dev_loss, summ], feed_dict={x: X, y: Y, xdev: Xdev, ydev: Ydev})\n",
    "            writer.add_summary(s, i)\n",
    "            writer.flush()\n",
    "        sess.run(train_step, feed_dict={x: X, y: Y, xdev: Xdev, ydev: Ydev})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net_models = ['CNN','FC']\n",
    "# net_models = ['RNN']\n",
    "\n",
    "def main():\n",
    "    for lr in [1e-2, 1e-3, 1e-4]:\n",
    "        for net_model in net_models:\n",
    "            niter = 500\n",
    "            fname = \"{},lr={}\".format(net_model, lr)\n",
    "        \n",
    "            submit(net_model, niter, lr, fname)\n",
    "    \n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
